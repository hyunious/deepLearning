{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding 을 위한 문자셋을 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 이름 성별 데이터 불러오기\n",
    "df = pd.read_csv('name_gender_filtered.csv')\n",
    "\n",
    "# one hot encoding 을 위한 문자 집합 생성\n",
    "unique_chars = set()\n",
    "\n",
    "# set 집합에 문자열을 추가하면 해당 문자열을 낱개로 쪼개어 각각의 문자들을 하나의 인자로 인식하여 집합에 추가\n",
    "# 중복된 문자는 추가되지 않음.!!!\n",
    "for name in df['Name']:\n",
    "    unique_chars.update(name)\n",
    "\n",
    "# 문자 집합을 정렬  \n",
    "unique_chars = sorted(list(unique_chars))\n",
    "unique_chars = ''.join(unique_chars)\n",
    "print(unique_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Name to One-Hot Encoded Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/57/x1ssc9tx6pb3x54j1y3dqlcc0000gn/T/ipykernel_14868/765286707.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "n_letters = len(unique_chars)\n",
    "\n",
    "def name_to_tensor(name):\n",
    "    tensor = torch.zeros(len(name), n_letters)\n",
    "    for i, letter in enumerate(name):\n",
    "        letter_index = unique_chars.find(letter)\n",
    "        assert letter_index != -1, \"letter not found: \" + letter\n",
    "        tensor[i][letter_index] = 1\n",
    "    return tensor\n",
    "\n",
    "\n",
    "# 성별을 숫자(인덱스)로 변환\n",
    "gen2num = {'F': 0, 'M': 1}\n",
    "# 숫자(인덱스)를 성별로 변환\n",
    "num2gen = {0: 'F', 1: 'M'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xd_rnn import XD_RNN\n",
    "\n",
    "# 은닉층 수\n",
    "n_hidden = 128\n",
    "# 입력층 수, 은닉층 수, 출력층 수\n",
    "rnn_model = XD_RNN(n_letters, n_hidden, 2)\n",
    "\n",
    "# 학습률\n",
    "learning_rate = 0.0001\n",
    "# 학습 횟수\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Loss: 0.4253, Accuracy: 80.269083%\n",
      "Epoch 2/500, Loss: 0.3805, Accuracy: 83.225736%\n",
      "Epoch 3/500, Loss: 0.3764, Accuracy: 83.551240%\n",
      "Epoch 4/500, Loss: 0.3752, Accuracy: 83.670591%\n",
      "Epoch 5/500, Loss: 0.3735, Accuracy: 83.572940%\n",
      "Epoch 6/500, Loss: 0.3732, Accuracy: 83.735691%\n",
      "Epoch 7/500, Loss: 0.3721, Accuracy: 83.632615%\n",
      "Epoch 8/500, Loss: 0.3719, Accuracy: 83.936418%\n",
      "Epoch 9/500, Loss: 0.3719, Accuracy: 83.811642%\n",
      "Epoch 10/500, Loss: 0.3706, Accuracy: 84.061195%\n",
      "Epoch 11/500, Loss: 0.3716, Accuracy: 83.817067%\n",
      "Epoch 12/500, Loss: 0.3704, Accuracy: 83.898443%\n",
      "Epoch 13/500, Loss: 0.3704, Accuracy: 84.120870%\n",
      "Epoch 14/500, Loss: 0.3704, Accuracy: 83.827917%\n",
      "Epoch 15/500, Loss: 0.3702, Accuracy: 83.860468%\n",
      "Epoch 16/500, Loss: 0.3688, Accuracy: 84.050344%\n",
      "Epoch 17/500, Loss: 0.3690, Accuracy: 84.115445%\n",
      "Epoch 18/500, Loss: 0.3686, Accuracy: 83.952694%\n",
      "Epoch 19/500, Loss: 0.3681, Accuracy: 83.979819%\n",
      "Epoch 20/500, Loss: 0.3674, Accuracy: 83.887593%\n",
      "Epoch 21/500, Loss: 0.3664, Accuracy: 84.039494%\n",
      "Epoch 22/500, Loss: 0.3654, Accuracy: 84.012369%\n",
      "Epoch 23/500, Loss: 0.3638, Accuracy: 84.251071%\n",
      "Epoch 24/500, Loss: 0.3633, Accuracy: 84.289047%\n",
      "Epoch 25/500, Loss: 0.3599, Accuracy: 84.370423%\n",
      "Epoch 26/500, Loss: 0.3573, Accuracy: 84.782727%\n",
      "Epoch 27/500, Loss: 0.3546, Accuracy: 84.945478%\n",
      "Epoch 28/500, Loss: 0.3504, Accuracy: 85.043129%\n",
      "Epoch 29/500, Loss: 0.3476, Accuracy: 85.102805%\n",
      "Epoch 30/500, Loss: 0.3435, Accuracy: 85.276406%\n",
      "Epoch 31/500, Loss: 0.3398, Accuracy: 85.536809%\n",
      "Epoch 32/500, Loss: 0.3352, Accuracy: 85.688710%\n",
      "Epoch 33/500, Loss: 0.3322, Accuracy: 85.677860%\n",
      "Epoch 34/500, Loss: 0.3279, Accuracy: 86.269191%\n",
      "Epoch 35/500, Loss: 0.3234, Accuracy: 86.182390%\n",
      "Epoch 36/500, Loss: 0.3186, Accuracy: 86.708620%\n",
      "Epoch 37/500, Loss: 0.3133, Accuracy: 86.952748%\n",
      "Epoch 38/500, Loss: 0.3089, Accuracy: 87.180600%\n",
      "Epoch 39/500, Loss: 0.3053, Accuracy: 87.316226%\n",
      "Epoch 40/500, Loss: 0.2999, Accuracy: 87.554929%\n",
      "Epoch 41/500, Loss: 0.2949, Accuracy: 87.831606%\n",
      "Epoch 42/500, Loss: 0.2905, Accuracy: 88.054034%\n",
      "Epoch 43/500, Loss: 0.2857, Accuracy: 88.287311%\n",
      "Epoch 44/500, Loss: 0.2817, Accuracy: 88.309011%\n",
      "Epoch 45/500, Loss: 0.2761, Accuracy: 88.699615%\n",
      "Epoch 46/500, Loss: 0.2710, Accuracy: 88.802691%\n",
      "Epoch 47/500, Loss: 0.2668, Accuracy: 89.187870%\n",
      "Epoch 48/500, Loss: 0.2610, Accuracy: 89.312646%\n",
      "Epoch 49/500, Loss: 0.2554, Accuracy: 89.545923%\n",
      "Epoch 50/500, Loss: 0.2511, Accuracy: 89.914827%\n",
      "Epoch 51/500, Loss: 0.2457, Accuracy: 90.224055%\n",
      "Epoch 52/500, Loss: 0.2411, Accuracy: 90.218630%\n",
      "Epoch 53/500, Loss: 0.2360, Accuracy: 90.592958%\n",
      "Epoch 54/500, Loss: 0.2300, Accuracy: 90.875061%\n",
      "Epoch 55/500, Loss: 0.2258, Accuracy: 91.075788%\n",
      "Epoch 56/500, Loss: 0.2209, Accuracy: 91.086638%\n",
      "Epoch 57/500, Loss: 0.2174, Accuracy: 91.200564%\n",
      "Epoch 58/500, Loss: 0.2129, Accuracy: 91.580318%\n",
      "Epoch 59/500, Loss: 0.2070, Accuracy: 91.764770%\n",
      "Epoch 60/500, Loss: 0.2001, Accuracy: 92.139098%\n",
      "Epoch 61/500, Loss: 0.1963, Accuracy: 92.285575%\n",
      "Epoch 62/500, Loss: 0.1923, Accuracy: 92.649053%\n",
      "Epoch 63/500, Loss: 0.1862, Accuracy: 92.741279%\n",
      "Epoch 64/500, Loss: 0.1830, Accuracy: 92.806380%\n",
      "Epoch 65/500, Loss: 0.1780, Accuracy: 93.045082%\n",
      "Epoch 66/500, Loss: 0.1740, Accuracy: 93.110183%\n",
      "Epoch 67/500, Loss: 0.1687, Accuracy: 93.370585%\n",
      "Epoch 68/500, Loss: 0.1652, Accuracy: 93.533337%\n",
      "Epoch 69/500, Loss: 0.1612, Accuracy: 93.701514%\n",
      "Epoch 70/500, Loss: 0.1565, Accuracy: 94.021592%\n",
      "Epoch 71/500, Loss: 0.1529, Accuracy: 94.021592%\n",
      "Epoch 72/500, Loss: 0.1486, Accuracy: 94.200618%\n",
      "Epoch 73/500, Loss: 0.1426, Accuracy: 94.461021%\n",
      "Epoch 74/500, Loss: 0.1404, Accuracy: 94.498996%\n",
      "Epoch 75/500, Loss: 0.1368, Accuracy: 94.602072%\n",
      "Epoch 76/500, Loss: 0.1310, Accuracy: 95.046927%\n",
      "Epoch 77/500, Loss: 0.1269, Accuracy: 95.274779%\n",
      "Epoch 78/500, Loss: 0.1232, Accuracy: 95.339880%\n",
      "Epoch 79/500, Loss: 0.1201, Accuracy: 95.404980%\n",
      "Epoch 80/500, Loss: 0.1162, Accuracy: 95.551457%\n",
      "Epoch 81/500, Loss: 0.1128, Accuracy: 95.741333%\n",
      "Epoch 82/500, Loss: 0.1097, Accuracy: 95.828134%\n",
      "Epoch 83/500, Loss: 0.1055, Accuracy: 96.115662%\n",
      "Epoch 84/500, Loss: 0.1036, Accuracy: 96.235013%\n",
      "Epoch 85/500, Loss: 0.0992, Accuracy: 96.272989%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     46\u001b[39m loss = loss_fn(output, target_tensor)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# 손실 역전파\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m loss.backward()\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# 최적화 실행\u001b[39;00m\n\u001b[32m     50\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    514\u001b[39m         Tensor.backward,\n\u001b[32m    515\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    520\u001b[39m         inputs=inputs,\n\u001b[32m    521\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m torch.autograd.backward(\n\u001b[32m    523\u001b[39m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001b[32m    524\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    261\u001b[39m     retain_graph = create_graph\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m Variable._execution_engine.run_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    267\u001b[39m     tensors,\n\u001b[32m    268\u001b[39m     grad_tensors_,\n\u001b[32m    269\u001b[39m     retain_graph,\n\u001b[32m    270\u001b[39m     create_graph,\n\u001b[32m    271\u001b[39m     inputs,\n\u001b[32m    272\u001b[39m     allow_unreachable=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    273\u001b[39m     accumulate_grad=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    274\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# 최적화 알고리즘\n",
    "optimizer = Adam(rnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 손실 함수\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 모델 학습 설정\n",
    "rnn_model.train()\n",
    "\n",
    "\n",
    "# 학습 횟수만큼 반복\n",
    "for epoch in range(epochs):\n",
    "    # 데이터 셔플 - reference : https://blog.naver.com/frogsom1120/222127699322\n",
    "    shuffled_df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # 데이터 분할은 하지 않음.\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # 데이터 (rows) 학습 \n",
    "    for index, row in shuffled_df.iterrows():\n",
    "        # 이름을 텐서로 변환 (one-hot encoding)\n",
    "        input_tensor = name_to_tensor(row['Name'])\n",
    "        # 성별을 텐서로 변환\n",
    "        target_tensor = torch.tensor([gen2num[row['Gender']]], dtype=torch.long)\n",
    "\n",
    "        # 모델 은닉층(상태)를 얻어옴\n",
    "        hidden = rnn_model.get_hidden()\n",
    "\n",
    "        # 모델 그레디언트 초기화\n",
    "        rnn_model.zero_grad()\n",
    "\n",
    "        # rnn 학습\n",
    "        for char_index in range(input_tensor.size(0)):\n",
    "            # char tensor 추출 : 2차원 텐서 (1, 26)\n",
    "            char_tensor = input_tensor[char_index]\n",
    "            # name char 학습 : 1차원 텐서 (26)\n",
    "            output, hidden = rnn_model(char_tensor[None, :], hidden)\n",
    "\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = loss_fn(output, target_tensor)\n",
    "        # 손실 역전파\n",
    "        loss.backward()\n",
    "        # 최적화 실행\n",
    "        optimizer.step()\n",
    "\n",
    "        # 손실 합계 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 예측 결과 계산\n",
    "        predicted_index = torch.argmax(output, dim=1)\n",
    "\n",
    "        # 예측 결과 확인\n",
    "        correct_predictions += (predicted_index == target_tensor).sum().item()\n",
    "        total_predictions += 1\n",
    "\n",
    "\n",
    "    # 평균 손실 계산\n",
    "    avg_loss = total_loss / total_predictions\n",
    "    \n",
    "    # 정확도 계산\n",
    "    accuracy = 100 * correct_predictions / total_predictions\n",
    "\n",
    "    # 학습 횟수 출력\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:2f}%\")\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n"
     ]
    }
   ],
   "source": [
    "test_name = 'elsa'\n",
    "test_tensor = name_to_tensor(test_name)\n",
    "\n",
    "rnn_model.eval()\n",
    "\n",
    "hidden = rnn_model.get_hidden()\n",
    "\n",
    "for char_index in range(test_tensor.size(0)):\n",
    "    char_tensor = test_tensor[char_index]\n",
    "    output, hidden = rnn_model(char_tensor[None, :], hidden)\n",
    "\n",
    "\n",
    "# 예측 결과 확인\n",
    "predicted_index = torch.argmax(output, dim=1)\n",
    "print(num2gen[predicted_index.item()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
