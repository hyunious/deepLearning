{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Based Country Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 방법 2: 국적을 랜덤으로 선택한 뒤 그 국적 내 이름을 샘플링하여 학습함\n",
    "\n",
    "클래스 불균형 문제를 완하하기 위해 국적을 랜덤하게 선택한 후, 국적 내 이름 데이터를 샘플링하여 학습합니다. <br>\n",
    "(이를 위해 데이터를 국적별로 미리 분류하면 구현이 용이) \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding 을 위해 사용된 문자셋을 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country Count: 18, Countries=['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n",
      "Country Index: {'Arabic': 0, 'Chinese': 1, 'Czech': 2, 'Dutch': 3, 'English': 4, 'French': 5, 'German': 6, 'Greek': 7, 'Irish': 8, 'Italian': 9, 'Japanese': 10, 'Korean': 11, 'Polish': 12, 'Portuguese': 13, 'Russian': 14, 'Scottish': 15, 'Spanish': 16, 'Vietnamese': 17}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "df = pd.read_csv('name_country.csv')\n",
    "\n",
    "# 이름 리스트를 얻어옴\n",
    "name_data = df['Name'].to_list()\n",
    "# 국적 데이터를 얻어옴 \n",
    "country_data = df['Country'].to_list()\n",
    "\n",
    "# 국적 리스트를 구성 : set 을 이용하여 중복 제거 후 정렬\n",
    "country_list = sorted(set(country_data))\n",
    "country_count = len(country_list)\n",
    "print(f\"Country Count: {country_count}, Countries={country_list}\")\n",
    "\n",
    "# 국적 to 인덱스로 변환\n",
    "country_to_index = {country: i for i, country in enumerate(country_list)}\n",
    "print(f\"Country Index: {country_to_index}\")\n",
    "\n",
    "# collections.Counter를 사용하여 국적별 데이터 수 계산 (클래스별 불균형 데이터인지 확인하기 위함)\n",
    "# country_counts = Counter(country_data)\n",
    "# print(sorted(country_counts.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 국적별로 데이터들을 구성하는 dict를 생성\n",
    "# key - country, value - list of names\n",
    "data_dict = {}\n",
    "for name, country in zip(name_data, country_data):\n",
    "  if country not in data_dict:\n",
    "    data_dict[country] = []\n",
    "  data_dict[country].append(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Character Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "character count: 28, characters= 'abcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding 을 위한 문자 집합 생성\n",
    "unique_chars = set()\n",
    "\n",
    "# set 집합에 문자열을 추가하면 해당 문자열을 낱개로 쪼개어 각각의 문자들을 하나의 인자로 인식하여 집합에 추가\n",
    "# 중복된 문자는 추가되지 않음.!!!\n",
    "for name in name_data:\n",
    "    unique_chars.update(name)\n",
    "    if ',' in name:\n",
    "        print(f\"쉼표가 포함된 이름 발견: {name}\")\n",
    "\n",
    "# 문자 집합을 정렬  \n",
    "unique_chars = sorted(list(unique_chars))\n",
    "unique_chars = ''.join(unique_chars)\n",
    "print(f\"character count: {len(unique_chars)}, characters={unique_chars}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Name to One-Hot Encoded Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/57/x1ssc9tx6pb3x54j1y3dqlcc0000gn/T/ipykernel_5995/4140834305.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/hyunious/opt/anaconda3/envs/py312/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "n_letters = len(unique_chars)\n",
    "\n",
    "def name_to_tensor(name):\n",
    "    tensor = torch.zeros(len(name), n_letters)\n",
    "    for i, letter in enumerate(name):\n",
    "        letter_index = unique_chars.find(letter)\n",
    "        assert letter_index != -1, \"letter not found: \" + letter\n",
    "        tensor[i][letter_index] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xd_rnn import XD_RNN\n",
    "\n",
    "# 은닉층 수\n",
    "n_hidden = 32\n",
    "# 입력층 수, 은닉층 수, 출력층 수\n",
    "rnn_model = XD_RNN(n_letters, n_hidden, country_count)\n",
    "\n",
    "# 학습률\n",
    "learning_rate = 0.0001\n",
    "# 학습 횟수\n",
    "iter_count = 200000\n",
    "\n",
    "# 학습 상태 출력 기준 횟수\n",
    "print_iter_count = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter Index 5000, Loss: 2.1083, Accuracy: 33.540000%\n",
      "Iter Index 10000, Loss: 1.6700, Accuracy: 45.460000%\n",
      "Iter Index 15000, Loss: 1.4931, Accuracy: 50.320000%\n",
      "Iter Index 20000, Loss: 1.3910, Accuracy: 54.120000%\n",
      "Iter Index 25000, Loss: 1.2965, Accuracy: 57.340000%\n",
      "Iter Index 30000, Loss: 1.2422, Accuracy: 59.740000%\n",
      "Iter Index 35000, Loss: 1.2057, Accuracy: 61.280000%\n",
      "Iter Index 40000, Loss: 1.1332, Accuracy: 63.220000%\n",
      "Iter Index 45000, Loss: 1.0644, Accuracy: 65.820000%\n",
      "Iter Index 50000, Loss: 1.0383, Accuracy: 65.120000%\n",
      "Iter Index 55000, Loss: 0.9851, Accuracy: 67.460000%\n",
      "Iter Index 60000, Loss: 0.9709, Accuracy: 68.020000%\n",
      "Iter Index 65000, Loss: 0.8861, Accuracy: 70.500000%\n",
      "Iter Index 70000, Loss: 0.8990, Accuracy: 69.740000%\n",
      "Iter Index 75000, Loss: 0.8753, Accuracy: 70.860000%\n",
      "Iter Index 80000, Loss: 0.8494, Accuracy: 71.400000%\n",
      "Iter Index 85000, Loss: 0.8298, Accuracy: 72.720000%\n",
      "Iter Index 90000, Loss: 0.7719, Accuracy: 73.920000%\n",
      "Iter Index 95000, Loss: 0.7922, Accuracy: 74.240000%\n",
      "Iter Index 100000, Loss: 0.7817, Accuracy: 74.480000%\n",
      "Iter Index 105000, Loss: 0.7641, Accuracy: 75.420000%\n",
      "Iter Index 110000, Loss: 0.7550, Accuracy: 75.140000%\n",
      "Iter Index 115000, Loss: 0.7478, Accuracy: 75.320000%\n",
      "Iter Index 120000, Loss: 0.7231, Accuracy: 76.640000%\n",
      "Iter Index 125000, Loss: 0.7201, Accuracy: 76.640000%\n",
      "Iter Index 130000, Loss: 0.7308, Accuracy: 75.480000%\n",
      "Iter Index 135000, Loss: 0.7278, Accuracy: 76.760000%\n",
      "Iter Index 140000, Loss: 0.7190, Accuracy: 75.920000%\n",
      "Iter Index 145000, Loss: 0.7222, Accuracy: 76.260000%\n",
      "Iter Index 150000, Loss: 0.6881, Accuracy: 77.560000%\n",
      "Iter Index 155000, Loss: 0.6645, Accuracy: 77.780000%\n",
      "Iter Index 160000, Loss: 0.6971, Accuracy: 77.840000%\n",
      "Iter Index 165000, Loss: 0.6984, Accuracy: 77.560000%\n",
      "Iter Index 170000, Loss: 0.6639, Accuracy: 78.640000%\n",
      "Iter Index 175000, Loss: 0.7092, Accuracy: 77.020000%\n",
      "Iter Index 180000, Loss: 0.6595, Accuracy: 78.340000%\n",
      "Iter Index 185000, Loss: 0.6720, Accuracy: 78.440000%\n",
      "Iter Index 190000, Loss: 0.6748, Accuracy: 77.540000%\n",
      "Iter Index 195000, Loss: 0.6763, Accuracy: 77.700000%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "# 최적화 알고리즘\n",
    "optimizer = Adam(rnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 손실 함수\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 모델 학습 설정\n",
    "rnn_model.train()\n",
    "\n",
    "# 학습 상태 출력 기준 횟수별 loss, predictions\n",
    "current_loss = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "# iteration 만큼 국적별 이름 데이터 학습\n",
    "for iter_index in range(iter_count):\n",
    "    # 국적을 랜덤하게 선택\n",
    "    random_country = random.choice(country_list)\n",
    "    random_name = random.choice(data_dict[random_country])\n",
    "\n",
    "\n",
    "    # 데이터 (rows) 학습 \n",
    "    # 이름을 텐서로 변환 (one-hot encoding)\n",
    "    input_tensor = name_to_tensor(random_name)\n",
    "    # 국적을 텐서로 변환\n",
    "    target_tensor = torch.tensor([country_to_index[random_country]], dtype=torch.long)\n",
    "\n",
    "    # 모델 은닉층(상태)를 얻어옴\n",
    "    hidden = rnn_model.get_hidden()\n",
    "\n",
    "    # 모델 그레디언트 초기화\n",
    "    rnn_model.zero_grad()\n",
    "\n",
    "    # rnn 학습\n",
    "    for char_index in range(input_tensor.size(0)):\n",
    "        # char tensor 추출 : 2차원 텐서 (1, 28)\n",
    "        char_tensor = input_tensor[char_index]\n",
    "        # name char 학습 : 1차원 텐서 (28)\n",
    "        output, hidden = rnn_model(char_tensor[None, :], hidden)\n",
    "\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = loss_fn(output, target_tensor)\n",
    "    # 손실 역전파\n",
    "    loss.backward()\n",
    "    # 최적화 실행\n",
    "    optimizer.step()\n",
    "\n",
    "    # 손실 합계 계산\n",
    "    current_loss += loss.item()\n",
    "\n",
    "    # 예측 결과 계산\n",
    "    predicted_index = torch.argmax(output, dim=1)\n",
    "\n",
    "    # 예측 결과 확인\n",
    "    correct_predictions += (predicted_index == target_tensor).sum().item()\n",
    "\n",
    "    # 학습 구간별 학습 상태 출력\n",
    "    if iter_index % print_iter_count == 0 and iter_index != 0:\n",
    "        # 평균 손실 계산\n",
    "        avg_loss = current_loss / print_iter_count\n",
    "        # 정확도 계산\n",
    "        accuracy = 100 * correct_predictions / print_iter_count\n",
    "        # 학습 횟수 출력\n",
    "        print(f\"Iter Index {iter_index}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:2f}%\")\n",
    "\n",
    "        current_loss = 0\n",
    "        correct_predictions = 0\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output : tensor([[-12.3037,  -3.4915,   2.3845,  -0.4657,   5.0800,   1.8066,   4.3514,\n",
      "         -10.1124,   1.0809,  -6.1061,  -7.9661,  -1.6875,   3.8098, -11.9028,\n",
      "           3.0550,   1.1833,  -4.3765,  -4.1357]], grad_fn=<AddmmBackward0>)\n",
      "English\n"
     ]
    }
   ],
   "source": [
    "test_name = 'jinping'\n",
    "test_tensor = name_to_tensor(test_name)\n",
    "\n",
    "rnn_model.eval()\n",
    "\n",
    "hidden = rnn_model.get_hidden()\n",
    "\n",
    "for char_index in range(test_tensor.size(0)):\n",
    "    char_tensor = test_tensor[char_index]\n",
    "    output, hidden = rnn_model(char_tensor[None, :], hidden)\n",
    "\n",
    "print (f\"Output : {output}\")\n",
    "\n",
    "# 예측 결과 확인\n",
    "predicted_index = torch.argmax(output, dim=1)\n",
    "print(country_list[predicted_index.item()])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
